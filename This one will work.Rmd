---
title: "This one will be right"
author: "Gustav, Magnus, Morten, Nicoline, Tobias"
date: "10/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 - Part 2 - Diagnosing schizophrenia from voice

```{r}
# load libraries (Gustav)
pacman::p_load(tidyverse, groupdata2, caret, dplyr, knitr, e1071, cvms)

# load data (Magnus)
data <- read.csv("merged.csv")

# rename variables (Morten)
data <- data %>% rename(speechrate = speechrate..nsyll.dur., 
                duration = dur..s., 
                phonationtime = phonationtime..s.,
                articulation_rate = articulation.rate..nsyll...phonationtime.,
                asd = ASD..speakingtime.nsyll.,
                language = Language)

#create variables proportion of time spoken and pause duration (Nicoline)
data$pots <- data$phonationtime/data$duration
data$pause_dur <- (data$duration - data$phonationtime) / data$npause
data$pause_dur[is.infinite(data$pause_dur)] <- 0

# select data to be used (Tobias)
columns <- c("study", "diagnosis", "subject", "pots", "pause_dur", "iqr", "sd", "language")
data <- data %>% select(columns) %>% na.omit()
data$subject <- data$subject + data$diagnosis * 1000
data <- filter(data, language == 'Danish')

# write new file for data (Gustav)
write.csv(data, 'Dis_data_be_good_mon.csv')
```

Ensuring equal number of schiz vs no schiz - removing random values. 

```{r}
# find cases where diagnosis is 0 (Magnus)
find_norm <- data$diagnosis == 0

# finding difference in number of schiz and reg (Morten)
diff <- sum((data$diagnosis == 0) - (data$diagnosis == 1))

# select cases where diagnosis is 0 (Nicoline)
norm <- which(find_norm == TRUE)

# sample difference (Tobias)
remo <- sample(norm, diff)

# remove excess in diagnosis with most participants (Gustav)
data <- data[-remo, ]

# make factor (Magnus)
data$diagnosis <- as.factor(data$diagnosis)

# remove all na (Morten)
data <- na.omit(data)

# make summary of data (Nicoline)
str(data)
summary(data$diagnosis)
```

### Let's start

We first want to build a logistic regression to see whether you can diagnose schizophrenia from your best acoustic feature. Let's use the full dataset and calculate the different performance measures (accuracy, sensitivity, specificity, PPV, NPV, ROC curve). You need to think carefully as to how we should (or not) use study and subject ID.

```{r}
# make duplicate df (Tobias)
data2 <- data

# normalize and standardize data (Gustav)
pre_proc_values <- preProcess(data2, method = c("center", "scale"))

# predict (Magnus)
data2 <- predict(pre_proc_values, data2)
```


```{r}
# create model (Morten)
model <- glm(diagnosis ~ pause_dur, data = data2, family = binomial)

# create predictions (Nicoline)
data2$pred <- predict(model)

# make factor (Tobias)
data2$diagnosis_pred <- as.factor(ifelse(data2$pred < 0, "0", "1"))

# make subject factor (Gustav)
data2$subject <- as.factor(data2$subject)

# make diagnosis factor (Magnus)
data2$diagnosis <- as.factor(data2$diagnosis)

# make confusion matrix (Morten)
confusionMatrix(data = data2$diagnosis_pred, reference = data2$diagnosis)
```


Then cross-validate the logistic regression and re-calculate performance on the testing folds. N.B. The cross-validation functions you already have should be tweaked: you need to calculate these new performance measures. Alternatively, the groupdata2 and cvms package created by Ludvig are an easy solution.

```{r}
# divide data into testing and training (Morten)
training <- subset(data, study != 4)
testing <- subset(data, study == 4)

# standardise and normalise training data (Nicoline)
train_pre_proc <- preProcess(training, method = c("center", "scale"))

# predict (Tobias)
training <- predict(train_pre_proc, training)

# standardise and normalise testing data (Gustav)
test_pre_proc <- preProcess(testing, method = c("center", "scale"))

# predict (Magnus)
testing <- predict(test_pre_proc, testing)

# make factor (Nicoline)
training$subject <- as.factor(training$subject)

# make folds (Nicoline)
training <- fold(
  training,
  k = 10,
  cat_col = "diagnosis",
  id_col = "subject",
  num_fold_cols = 5,
  handle_existing_fold_cols = "keep"
)

# Set seed for reproducibility (Tobias)
set.seed(1234)

# cross-validate (Gustav)
CV <- cross_validate(
  data = training,
  formulas = c("diagnosis ~ pots + sd + iqr",
               "diagnosis ~ pots + pause_dur + sd + iqr",
               "diagnosis ~ iqr + sd",
               "diagnosis ~ iqr + pause_dur",
               "diagnosis ~ sd + pots",
               "diagnosis ~ iqr",
               "diagnosis ~ sd",
               "diagnosis ~ pots",
               "diagnosis ~ pause_dur"),
  fold_cols = paste0(".folds_", 1:4),
  family = 'binomial'
)
# get cross-validations (Magnus)
CV
```


```{r}
# create model (Morten)
m <- glm(diagnosis ~ iqr + sd, data = training, family = binomial)

# create predictions (Nicoline)
testing$pred <- predict(m, newdata = testing, allow.new.levels = TRUE)

# make factor (Tobias)
testing$diagnosis_pred <- as.factor(ifelse(testing$pred < 0, "0", "1"))

# make subject factor (Gustav)
testing$subject <- as.factor(testing$subject)

# make diagnosis factor (Magnus)
testing$diagnosis <- as.factor(testing$diagnosis)

# make confusion matrix (Morten)
confusionMatrix(data = testing$diagnosis_pred, reference = testing$diagnosis)
```


N.B. the predict() function generates log odds (the full scale between minus and plus infinity). Log odds > 0 indicates a choice of 1, below a choice of 0.
N.N.B. you need to decide whether calculate performance on each single test fold or save all the prediction for test folds in one datase, so to calculate overall performance.
N.N.N.B. Now you have two levels of structure: subject and study. Should this impact your cross-validation?
N.N.N.N.B. A more advanced solution could rely on the tidymodels set of packages (warning: Time-consuming to learn as the documentation is sparse, but totally worth it)